"""
è¿½æ¼«é˜ - æ•°æ®å¤‡ä»½ä¸æ¢å¤
"""
import json
import logging
import os
import tempfile
import hashlib
from datetime import datetime
import requests
from app import config
from app.db import database as db

logger = logging.getLogger(__name__)


def export_data() -> dict:
    """
    å¯¼å‡ºæ‰€æœ‰æ•°æ®ä¸ºå­—å…¸

    Returns:
        åŒ…å«æ‰€æœ‰è¿½æ›´æ•°æ®çš„å­—å…¸
    """
    animes = db.get_all_animes()
    result = {
        "version": "1.0",
        "exported_at": datetime.now().isoformat(),
        "app": "è¿½æ¼«é˜",
        "animes": [],
        "settings": db.get_all_settings(),
    }

    for anime in animes:
        aid = anime["id"]
        episodes = db.get_episodes(aid)
        aliases = db.get_aliases(aid)
        rules = db.get_source_rules(aid)

        # æ¯é›†é™„å¸¦è§†é¢‘æº
        ep_list = []
        for ep in episodes:
            sources = db.get_sources_for_episode(ep["id"])
            ep["sources"] = sources
            ep_list.append(ep)

        anime_data = {
            "anime": anime,
            "episodes": ep_list,
            "aliases": aliases,
            "rules": rules,
        }
        result["animes"].append(anime_data)

    return result


def export_json() -> str:
    """å¯¼å‡ºä¸º JSON å­—ç¬¦ä¸²"""
    data = export_data()
    return json.dumps(data, ensure_ascii=False, indent=2, default=str)


def import_data(data: dict) -> dict:
    """
    ä»å­—å…¸å¯¼å…¥æ•°æ®ï¼ˆåˆå¹¶æ¨¡å¼ï¼Œä¸ä¼šåˆ é™¤ç°æœ‰æ•°æ®ï¼‰

    Args:
        data: export_data() æ ¼å¼çš„å­—å…¸

    Returns:
        å¯¼å…¥ç»“æœç»Ÿè®¡
    """
    stats = {"animes_imported": 0, "episodes_imported": 0, "sources_imported": 0, "skipped": 0}

    for anime_entry in data.get("animes", []):
        anime_info = anime_entry.get("anime", {})
        tmdb_id = anime_info.get("tmdb_id")

        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        existing = None
        if tmdb_id:
            existing = db.get_anime_by_tmdb_id(tmdb_id)

        if existing:
            anime_id = existing["id"]
            stats["skipped"] += 1
            # æ›´æ–°è§‚çœ‹è¿›åº¦ï¼ˆå–è¾ƒå¤§å€¼ï¼‰
            if (anime_info.get("watched_ep") or 0) > (existing.get("watched_ep") or 0):
                db.update_anime(anime_id, {"watched_ep": anime_info["watched_ep"]})
        else:
            # æ–°å¢åŠ¨æ¼«
            anime_id = db.add_anime({
                "title_cn": anime_info.get("title_cn", ""),
                "title_en": anime_info.get("title_en", ""),
                "tmdb_id": tmdb_id,
                "poster_url": anime_info.get("poster_url", ""),
                "overview": anime_info.get("overview", ""),
                "air_date": anime_info.get("air_date", ""),
                "status": anime_info.get("status", ""),
                "total_episodes": anime_info.get("total_episodes", 0),
                "watched_ep": anime_info.get("watched_ep", 0),
            })
            stats["animes_imported"] += 1

        # å¯¼å…¥é›†æ•°
        episodes_data = anime_entry.get("episodes", [])
        if episodes_data:
            existing_eps = {ep["absolute_num"] for ep in db.get_episodes(anime_id)}
            new_eps = []
            for ep in episodes_data:
                if ep.get("absolute_num") not in existing_eps:
                    new_eps.append({
                        "season_number": ep.get("season_number", 1),
                        "episode_number": ep.get("episode_number", 0),
                        "absolute_num": ep.get("absolute_num", 0),
                        "title": ep.get("title", ""),
                        "overview": ep.get("overview", ""),
                        "air_date": ep.get("air_date", ""),
                    })
            if new_eps:
                db.add_episodes(anime_id, new_eps)
                stats["episodes_imported"] += len(new_eps)

            # æ¢å¤å·²çœ‹çŠ¶æ€
            for ep in episodes_data:
                if ep.get("watched"):
                    db.mark_episode_watched(anime_id, ep["absolute_num"], True)

            # å¯¼å…¥è§†é¢‘æº
            for ep in episodes_data:
                for src in ep.get("sources", []):
                    episode_obj = db.get_episode_by_num(anime_id, ep["absolute_num"])
                    if episode_obj:
                        try:
                            db.add_source({
                                "episode_id": episode_obj["id"],
                                "video_id": src.get("video_id", ""),
                                "title": src.get("title", ""),
                                "channel_name": src.get("channel_name", ""),
                                "channel_id": src.get("channel_id", ""),
                                "duration": src.get("duration", 0),
                                "view_count": src.get("view_count", 0),
                                "published_at": src.get("published_at", ""),
                                "match_score": src.get("match_score", 0),
                            })
                            stats["sources_imported"] += 1
                        except Exception:
                            pass  # é‡å¤çš„è§†é¢‘æºè·³è¿‡

        # å¯¼å…¥åˆ«å
        for alias in anime_entry.get("aliases", []):
            try:
                db.add_alias(anime_id, alias)
            except Exception:
                pass

        # å¯¼å…¥è§„åˆ™
        rules = anime_entry.get("rules")
        if rules:
            db.set_source_rules(anime_id, rules)

    # å¯¼å…¥è®¾ç½®
    for key, value in data.get("settings", {}).items():
        db.set_setting(key, str(value))

    return stats


def send_backup_to_telegram() -> dict:
    """
    å°†å¤‡ä»½ JSON é€šè¿‡ Telegram Bot å‘é€

    Returns:
        å‘é€ç»“æœ
    """
    # ä¼˜å…ˆä»è®¾ç½®è¯»å–ï¼ˆUI é…ç½®ï¼‰ï¼Œå›é€€åˆ° configï¼ˆç¯å¢ƒå˜é‡ï¼‰
    token = db.get_setting("tg_bot_token", "") or config.TG_BOT_TOKEN
    chat_id = db.get_setting("tg_chat_id", "") or config.TG_CHAT_ID

    if not token or not chat_id:
        error_msg = "æœªé…ç½® TG_BOT_TOKEN æˆ– TG_CHAT_ID"
        logger.warning(error_msg)
        db.add_backup_log("telegram", "error", error_msg, 0, "", "NO_CONFIG")
        return {"success": False, "error": error_msg}

    tmp_path = None
    file_size = 0
    
    try:
        json_str = export_json()
        file_size = len(json_str.encode('utf-8'))
        now = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"zhuimange_backup_{now}.json"

        # é€šè¿‡ sendDocument API å‘é€æ–‡ä»¶
        url = f"https://api.telegram.org/bot{token}/sendDocument"

        # å†™å…¥ä¸´æ—¶æ–‡ä»¶
        tmp = tempfile.NamedTemporaryFile(
            mode="w", suffix=".json", delete=False, encoding="utf-8"
        )
        tmp.write(json_str)
        tmp.close()
        tmp_path = tmp.name

        with open(tmp.name, "rb") as f:
            resp = requests.post(
                url,
                data={"chat_id": chat_id, "caption": f"ğŸ“¦ è¿½æ¼«é˜å¤‡ä»½ {now}"},
                files={"document": (filename, f, "application/json")},
                timeout=30,
            )

        if resp.status_code == 200 and resp.json().get("ok"):
            logger.info(f"Telegram å¤‡ä»½å‘é€æˆåŠŸ: {filename}")
            db.add_backup_log("telegram", "success", "å¤‡ä»½å‘é€æˆåŠŸ", file_size, filename)
            return {"success": True, "filename": filename}
        else:
            error = resp.json().get("description", resp.text)
            error_code = resp.json().get("error_code", "TG_API_ERROR")
            logger.error(f"Telegram å¤‡ä»½å‘é€å¤±è´¥: {error}")
            db.add_backup_log("telegram", "error", error, 0, filename, error_code)
            return {"success": False, "error": error}

    except requests.exceptions.Timeout:
        error_msg = "Telegram API è¯·æ±‚è¶…æ—¶"
        logger.error(error_msg)
        db.add_backup_log("telegram", "error", error_msg, 0, "", "TIMEOUT")
        return {"success": False, "error": error_msg}
    except requests.exceptions.RequestException as e:
        error_msg = f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}"
        logger.error(f"Telegram å¤‡ä»½å¼‚å¸¸: {e}")
        db.add_backup_log("telegram", "error", error_msg, 0, "", "NETWORK_ERROR")
        return {"success": False, "error": error_msg}
    except Exception as e:
        error_msg = f"å¤‡ä»½å¼‚å¸¸: {str(e)}"
        logger.error(f"Telegram å¤‡ä»½å¼‚å¸¸: {e}")
        db.add_backup_log("telegram", "error", error_msg, 0, "", "UNKNOWN_ERROR")
        return {"success": False, "error": str(e)}
    finally:
        if tmp_path and os.path.exists(tmp_path):
            try:
                os.unlink(tmp_path)
            except Exception as e:
                logger.warning(f"ä¸´æ—¶æ–‡ä»¶æ¸…ç†å¤±è´¥: {e}")


def calculate_backup_checksum(data: dict) -> str:
    """è®¡ç®—å¤‡ä»½æ•°æ®çš„æ ¡éªŒå’Œ
    
    Args:
        data: å¤‡ä»½æ•°æ®å­—å…¸
    
    Returns:
        SHA256 å“ˆå¸Œå€¼
    """
    json_str = json.dumps(data, ensure_ascii=False, sort_keys=True, default=str)
    return hashlib.sha256(json_str.encode('utf-8')).hexdigest()


def verify_backup_integrity(data: dict, expected_checksum: str = None) -> dict:
    """éªŒè¯å¤‡ä»½æ•°æ®çš„å®Œæ•´æ€§
    
    Args:
        data: å¤‡ä»½æ•°æ®å­—å…¸
        expected_checksum: æœŸæœ›çš„æ ¡éªŒå’Œï¼ˆå¯é€‰ï¼‰
    
    Returns:
        éªŒè¯ç»“æœå­—å…¸
    """
    result = {
        "valid": True,
        "checksum": "",
        "checksum_match": False,
        "animes_count": 0,
        "episodes_count": 0,
        "sources_count": 0,
        "errors": []
    }
    
    # æ£€æŸ¥åŸºæœ¬ç»“æ„
    if data.get("app") != "è¿½æ¼«é˜":
        result["valid"] = False
        result["errors"].append("æ— æ•ˆçš„å¤‡ä»½æ–‡ä»¶æ ‡è¯†")
    
    if "animes" not in data:
        result["valid"] = False
        result["errors"].append("ç¼ºå°‘ animes æ•°æ®")
    else:
        result["animes_count"] = len(data["animes"])
    
    # ç»Ÿè®¡æ•°æ®é‡
    episodes_count = 0
    sources_count = 0
    for anime_entry in data.get("animes", []):
        episodes = anime_entry.get("episodes", [])
        episodes_count += len(episodes)
        for ep in episodes:
            sources_count += len(ep.get("sources", []))
    
    result["episodes_count"] = episodes_count
    result["sources_count"] = sources_count
    
    # è®¡ç®—æ ¡éªŒå’Œ
    result["checksum"] = calculate_backup_checksum(data)
    
    # éªŒè¯æ ¡éªŒå’Œ
    if expected_checksum:
        result["checksum_match"] = result["checksum"] == expected_checksum
        if not result["checksum_match"]:
            result["valid"] = False
            result["errors"].append("æ ¡éªŒå’Œä¸åŒ¹é…")
    
    return result


def save_backup_local(backup_dir: str = None) -> dict:
    """ä¿å­˜å¤‡ä»½åˆ°æœ¬åœ°æ–‡ä»¶
    
    Args:
        backup_dir: å¤‡ä»½ç›®å½•è·¯å¾„ï¼Œé»˜è®¤ä¸º data/backups
    
    Returns:
        å¤‡ä»½ç»“æœ
    """
    import os
    
    if not backup_dir:
        base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        backup_dir = os.path.join(base_dir, "data", "backups")
    
    try:
        os.makedirs(backup_dir, exist_ok=True)
        
        data = export_data()
        json_str = json.dumps(data, ensure_ascii=False, indent=2, default=str)
        checksum = calculate_backup_checksum(data)
        
        now = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"zhuimange_backup_{now}.json"
        filepath = os.path.join(backup_dir, filename)
        
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(json_str)
        
        file_size = os.path.getsize(filepath)
        
        logger.info(f"æœ¬åœ°å¤‡ä»½æˆåŠŸ: {filename}, å¤§å°: {file_size} å­—èŠ‚")
        db.add_backup_log("local", "success", "å¤‡ä»½ä¿å­˜æˆåŠŸ", file_size, filename)
        
        return {
            "success": True,
            "filename": filename,
            "filepath": filepath,
            "file_size": file_size,
            "checksum": checksum
        }
        
    except OSError as e:
        error_msg = f"æ–‡ä»¶ç³»ç»Ÿé”™è¯¯: {str(e)}"
        logger.error(f"æœ¬åœ°å¤‡ä»½å¤±è´¥: {error_msg}")
        db.add_backup_log("local", "error", error_msg, 0, "", "FILESYSTEM_ERROR")
        return {"success": False, "error": error_msg}
    except Exception as e:
        error_msg = f"æœ¬åœ°å¤‡ä»½å¼‚å¸¸: {str(e)}"
        logger.error(f"æœ¬åœ°å¤‡ä»½å¼‚å¸¸: {e}")
        db.add_backup_log("local", "error", error_msg, 0, "", "UNKNOWN_ERROR")
        return {"success": False, "error": error_msg}
